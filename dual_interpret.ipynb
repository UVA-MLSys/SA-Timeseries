{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import *\n",
    "from tint.metrics import mse, mae\n",
    "import tint, captum\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.explainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import (\n",
    "    DeepLift,\n",
    "    GradientShap,\n",
    "    IntegratedGradients,\n",
    "    Lime\n",
    ")\n",
    "\n",
    "from tint.attr import (\n",
    "    AugmentedOcclusion,\n",
    "    DynaMask,\n",
    "    Occlusion, \n",
    "    Fit, FeatureAblation,\n",
    "    TimeForwardTunnel\n",
    ")\n",
    "\n",
    "from tint.attr import (\n",
    "    TemporalAugmentedOcclusion,\n",
    "    TemporalIntegratedGradients,\n",
    "    TemporalOcclusion,\n",
    "    TimeForwardTunnel,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser()\n",
    "argv = \"\"\"\n",
    "  --root_path ./dataset/illness/ \\\n",
    "  --data_path national_illness.csv \\\n",
    "  --model DLinear \\\n",
    "  --use_gpu\n",
    "  --features MS \\\n",
    "  --seq_len 36 \\\n",
    "  --label_len 12 \\\n",
    "  --pred_len 24 \\\n",
    "  --n_features 7\n",
    "\"\"\".split()\n",
    "args = parser.parse_args(argv)\n",
    "\n",
    "# Disable cudnn if using cuda accelerator.\n",
    "# Please see https://captum.ai/docs/faq#how-can-i-resolve-cudnn-rnn-backward-error-for-rnn-or-lstm-network\n",
    "# args.use_gpu = False\n",
    "initial_setup(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.explainers = [\n",
    "    \"deep_lift\",\n",
    "    \"gradient_shap\",\n",
    "    \"integrated_gradients\",\n",
    "    \"lime\",\n",
    "    \"occlusion\",\n",
    "    \"augmented_occlusion\",\n",
    "]\n",
    "\n",
    "args.areas = [\n",
    "    0.05, 0.1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_name_map = {\n",
    "    \"deep_lift\":DeepLift,\n",
    "    \"gradient_shap\":GradientShap,\n",
    "    \"integrated_gradients\":IntegratedGradients,\n",
    "    \"lime\":Lime,\n",
    "    \"occlusion\":Occlusion,\n",
    "    \"augmented_occlusion\":AugmentedOcclusion,\n",
    "    \"dyna_mask\":DynaMask,\n",
    "    \"feature_ablation\":FeatureAblation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Experiments will be saved in ./results\\national_illness_DLinear\n",
      "test 73\n",
      "Loading model from ./results\\national_illness_DLinear\\checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "assert args.task_name == 'long_term_forecast', \"Only long_term_forecast is supported for now\"\n",
    "\n",
    "exp = Exp_Long_Term_Forecast(args)  # set experiments\n",
    "_, dataloader = exp._get_data('test')\n",
    "exp.load_best_model()\n",
    "\n",
    "model = exp.model\n",
    "model.eval()\n",
    "# model.zero_grad()\n",
    "\n",
    "# only need to output targets, sinec interpretation is based on outputs\n",
    "assert not exp.args.output_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_metrics = ['mae', 'mse']\n",
    "# expl_metrics = [getattr(tint.metrics, metric_name) for metric_name in expl_metrics]\n",
    "areas = [0.05, 0.075, 0.1]\n",
    "\n",
    "explainers = ['deep_lift', 'feature_ablation'] # explainers = args.explainers\n",
    "explainers_map = dict()\n",
    "for name in explainers:\n",
    "    if name == 'augmented_occlusion':\n",
    "        inputs = get_total_data(dataloader)\n",
    "        explainers_map[name] = explainer_name_map[name](model, inputs)\n",
    "    else:    \n",
    "        explainers_map[name] = explainer_name_map[name](model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:17<00:00,  5.79s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "baseline_mode = \"random\" # \"zeros\", \"aug\"\n",
    "result_columns = ['batch_index', 'explainer', 'metric', 'area', 'comp', 'suff']\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    enumerate(dataloader), total=len(dataloader), disable=False\n",
    ")\n",
    "for batch_index, (batch_x, batch_y, batch_x_mark, batch_y_mark) in progress_bar:\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()\n",
    "    # outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    \n",
    "    inputs = (batch_x, batch_x_mark)\n",
    "    # baseline must be a scaler or tuple of tensors with same dimension as input\n",
    "    baselines = get_baseline(inputs, baseline_mode)\n",
    "    additional_forward_args = (dec_inp, batch_y_mark)\n",
    "\n",
    "    # get attributions\n",
    "    for name in explainers:\n",
    "        explainer = explainers_map[name]\n",
    "        attr = compute_attr(\n",
    "            inputs, baselines, explainer, additional_forward_args, args\n",
    "        )\n",
    "    \n",
    "        # get scores\n",
    "        for area in areas:\n",
    "            for metric_name in ['mae', 'mse']:\n",
    "                metric = getattr(tint.metrics, metric_name)\n",
    "                error_comp = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=True\n",
    "                )\n",
    "                \n",
    "                error_suff = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=False\n",
    "                )\n",
    "           \n",
    "                result_row = [batch_index, name, metric_name, area, error_comp, error_suff]\n",
    "                # print(result_row)\n",
    "                results.append(result_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           explainer metric   area        comp       suff\n",
      "0          deep_lift    mae  0.050   35.556379  34.244208\n",
      "1          deep_lift    mae  0.075   49.028145  21.650221\n",
      "2          deep_lift    mae  0.100   61.907148  11.877960\n",
      "3          deep_lift    mse  0.050   54.197291  54.057170\n",
      "4          deep_lift    mse  0.075  102.314908  23.969013\n",
      "5          deep_lift    mse  0.100  162.540655   8.745565\n",
      "6   feature_ablation    mae  0.050   35.368984  34.748280\n",
      "7   feature_ablation    mae  0.075   48.341543  21.994582\n",
      "8   feature_ablation    mae  0.100   61.186089  12.291678\n",
      "9   feature_ablation    mse  0.050   53.678370  55.767656\n",
      "10  feature_ablation    mse  0.075   99.778231  24.854508\n",
      "11  feature_ablation    mse  0.100  159.409729   9.544050\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=result_columns)\n",
    "results_df = results_df.groupby(['explainer', 'metric', 'area'])[['comp', 'suff']].aggregate('mean').reset_index()\n",
    "# results_df.round(6).to_csv(os.path.join(result_folder, 'interpretation_results.csv'), index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y, batch_x_mark, batch_y_mark = next(iter(dataloader))\n",
    "batch_x = batch_x.float().to(exp.device)\n",
    "batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "# decoder input\n",
    "dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = (batch_x, batch_x_mark)\n",
    "additional_forward_args = (dec_inp, batch_y_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type                  | Params\n",
      "-----------------------------------------------\n",
      "0 | net  | JointFeatureGenerator | 38.6 K\n",
      "-----------------------------------------------\n",
      "38.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.6 K    Total params\n",
      "0.154     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24b738c756949d897f136323b002c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    }
   ],
   "source": [
    "data = get_total_data(dataloader, exp.device, add_x_mark=False)\n",
    "explainer = Fit(model, features=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [32, 2] but got: [32, 36].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Softwares\\SA-Timeseries\\dual_interpret.ipynb Cell 14\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m attr \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mattribute(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     batch_x, additional_forward_args\u001b[39m=\u001b[39;49m(batch_x_mark, dec_inp, batch_y_mark)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\captum\\log\\__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tint\\attr\\fit.py:221\u001b[0m, in \u001b[0;36mFit.attribute\u001b[1;34m(self, inputs, additional_forward_args, n_samples, distance_metric, multilabel, temporal_additional_forward_args, return_temporal_attributions, show_progress)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m return_temporal_attributions:\n\u001b[0;32m    214\u001b[0m     data, additional_forward_args, _ \u001b[39m=\u001b[39m _add_temporal_mask(\n\u001b[0;32m    215\u001b[0m         inputs\u001b[39m=\u001b[39mdata,\n\u001b[0;32m    216\u001b[0m         additional_forward_args\u001b[39m=\u001b[39madditional_forward_args,\n\u001b[0;32m    217\u001b[0m         temporal_additional_forward_args\u001b[39m=\u001b[39mtemporal_additional_forward_args,\n\u001b[0;32m    218\u001b[0m     )\n\u001b[0;32m    220\u001b[0m attributions \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresentation(\n\u001b[0;32m    222\u001b[0m         inputs\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    223\u001b[0m         additional_forward_args\u001b[39m=\u001b[39;49madditional_forward_args,\n\u001b[0;32m    224\u001b[0m         n_samples\u001b[39m=\u001b[39;49mn_samples,\n\u001b[0;32m    225\u001b[0m         distance_metric\u001b[39m=\u001b[39;49mdistance_metric,\n\u001b[0;32m    226\u001b[0m         multilabel\u001b[39m=\u001b[39;49mmultilabel,\n\u001b[0;32m    227\u001b[0m         temporal_additional_forward_args\u001b[39m=\u001b[39;49mtemporal_additional_forward_args,\n\u001b[0;32m    228\u001b[0m         show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m    229\u001b[0m     ),\n\u001b[0;32m    230\u001b[0m )\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m return_temporal_attributions:\n\u001b[0;32m    233\u001b[0m     attributions \u001b[39m=\u001b[39m (\n\u001b[0;32m    234\u001b[0m         attributions[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]) \u001b[39m+\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:]),\n\u001b[0;32m    235\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tint\\attr\\fit.py:300\u001b[0m, in \u001b[0;36mFit.representation\u001b[1;34m(self, inputs, additional_forward_args, n_samples, distance_metric, multilabel, temporal_additional_forward_args, show_progress)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m t_range:\n\u001b[0;32m    293\u001b[0m     partial_inputs, kwargs_copy \u001b[39m=\u001b[39m _slice_to_time(\n\u001b[0;32m    294\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    295\u001b[0m         time\u001b[39m=\u001b[39mt \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m    296\u001b[0m         additional_forward_args\u001b[39m=\u001b[39madditional_forward_args,\n\u001b[0;32m    297\u001b[0m         temporal_additional_forward_args\u001b[39m=\u001b[39mtemporal_additional_forward_args,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[0;32m    299\u001b[0m     p_y_t \u001b[39m=\u001b[39m activation(\n\u001b[1;32m--> 300\u001b[0m         _run_forward(\n\u001b[0;32m    301\u001b[0m             forward_func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_func,\n\u001b[0;32m    302\u001b[0m             inputs\u001b[39m=\u001b[39;49mpartial_inputs,\n\u001b[0;32m    303\u001b[0m             additional_forward_args\u001b[39m=\u001b[39;49mkwargs_copy[\n\u001b[0;32m    304\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39madditional_forward_args\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    305\u001b[0m             ],\n\u001b[0;32m    306\u001b[0m         )\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    309\u001b[0m     partial_inputs, kwargs_copy \u001b[39m=\u001b[39m _slice_to_time(\n\u001b[0;32m    310\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    311\u001b[0m         time\u001b[39m=\u001b[39mt,\n\u001b[0;32m    312\u001b[0m         additional_forward_args\u001b[39m=\u001b[39madditional_forward_args,\n\u001b[0;32m    313\u001b[0m         temporal_additional_forward_args\u001b[39m=\u001b[39mtemporal_additional_forward_args,\n\u001b[0;32m    314\u001b[0m     )\n\u001b[0;32m    315\u001b[0m     p_tm1 \u001b[39m=\u001b[39m activation(\n\u001b[0;32m    316\u001b[0m         _run_forward(\n\u001b[0;32m    317\u001b[0m             forward_func\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    322\u001b[0m         )\n\u001b[0;32m    323\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\captum\\_utils\\common.py:482\u001b[0m, in \u001b[0;36m_run_forward\u001b[1;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[0;32m    479\u001b[0m inputs \u001b[39m=\u001b[39m _format_inputs(inputs)\n\u001b[0;32m    480\u001b[0m additional_forward_args \u001b[39m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m--> 482\u001b[0m output \u001b[39m=\u001b[39m forward_func(\n\u001b[0;32m    483\u001b[0m     \u001b[39m*\u001b[39;49m(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49madditional_forward_args)\n\u001b[0;32m    484\u001b[0m     \u001b[39mif\u001b[39;49;00m additional_forward_args \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m    485\u001b[0m     \u001b[39melse\u001b[39;49;00m inputs\n\u001b[0;32m    486\u001b[0m )\n\u001b[0;32m    487\u001b[0m \u001b[39mreturn\u001b[39;00m _select_targets(output, target)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Softwares\\SA-Timeseries\\models\\DLinear.py:102\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x_enc, x_mark_enc, x_dec, x_mark_dec, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlong_term_forecast\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mshort_term_forecast\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 102\u001b[0m         dec_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforecast(x_enc)\n\u001b[0;32m    103\u001b[0m         f_dim \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfigs\u001b[39m.\u001b[39mfeatures \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMS\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m dec_out[:, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_len:, f_dim:]  \u001b[39m# [B, L, D]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Softwares\\SA-Timeseries\\models\\DLinear.py:80\u001b[0m, in \u001b[0;36mModel.forecast\u001b[1;34m(self, x_enc)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforecast\u001b[39m(\u001b[39mself\u001b[39m, x_enc):\n\u001b[0;32m     79\u001b[0m     \u001b[39m# Encoder\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x_enc)\n",
      "File \u001b[1;32mc:\\Softwares\\SA-Timeseries\\models\\DLinear.py:73\u001b[0m, in \u001b[0;36mModel.encoder\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     70\u001b[0m         trend_output[:, i, :] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLinear_Trend[i](\n\u001b[0;32m     71\u001b[0m             trend_init[:, i, :])\n\u001b[0;32m     72\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m     seasonal_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mLinear_Seasonal(seasonal_init)\n\u001b[0;32m     74\u001b[0m     trend_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLinear_Trend(trend_init)\n\u001b[0;32m     75\u001b[0m x \u001b[39m=\u001b[39m seasonal_output \u001b[39m+\u001b[39m trend_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [32, 2] but got: [32, 36]."
     ]
    }
   ],
   "source": [
    "attr = explainer.attribute(\n",
    "    batch_x, additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = DynaMask(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Multiple inputs are not accepted for this method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Softwares\\SA-Timeseries\\dual_interpret.ipynb Cell 22\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m attr \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mattribute(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     inputs\u001b[39m=\u001b[39;49m(batch_x, batch_x_mark),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     additional_forward_args\u001b[39m=\u001b[39;49m(dec_inp, batch_y_mark)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\captum\\log\\__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tint\\attr\\dynamic_masks.py:143\u001b[0m, in \u001b[0;36mDynaMask.attribute\u001b[1;34m(self, inputs, additional_forward_args, trainer, mask_net, batch_size, temporal_additional_forward_args, return_temporal_attributions, return_best_ratio)\u001b[0m\n\u001b[0;32m    139\u001b[0m     trainer \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(trainer)\n\u001b[0;32m    141\u001b[0m \u001b[39m# Assert only one input, as the Retain only accepts one\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mlen\u001b[39m(inputs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    144\u001b[0m ), \u001b[39m\"\u001b[39m\u001b[39mMultiple inputs are not accepted for this method\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m data \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    147\u001b[0m \u001b[39m# If return temporal attr, we expand the input data\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39m# and multiply it with a lower triangular mask\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Multiple inputs are not accepted for this method"
     ]
    }
   ],
   "source": [
    "attr = explainer.attribute(\n",
    "    inputs=(batch_x, batch_x_mark),\n",
    "    additional_forward_args=(dec_inp, batch_y_mark)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeForwardTunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (25) must match the size of tensor b (36) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Softwares\\SA-Timeseries\\dual_interpret.ipynb Cell 25\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m explainer \u001b[39m=\u001b[39m TimeForwardTunnel(GradientShap(model))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m attr \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mattribute(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     inputs\u001b[39m=\u001b[39;49mbatch_x, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     baselines\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     n_samples\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, stdevs \u001b[39m=\u001b[39;49m \u001b[39m0.0001\u001b[39;49m, return_temporal_attributions\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     task\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mregression\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     additional_forward_args\u001b[39m=\u001b[39;49m(batch_x_mark, dec_inp, batch_y_mark)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\captum\\log\\__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tint\\attr\\time_forward_tunnel.py:177\u001b[0m, in \u001b[0;36mTimeForwardTunnel.attribute\u001b[1;34m(self, inputs, task, threshold, temporal_target, temporal_additional_forward_args, return_temporal_attributions, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39m# Compute attributions over time\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39mfor\u001b[39;00m time \u001b[39min\u001b[39;00m times:\n\u001b[1;32m--> 177\u001b[0m     partial_inputs, kwargs_copy \u001b[39m=\u001b[39m _slice_to_time(\n\u001b[0;32m    178\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    179\u001b[0m         time\u001b[39m=\u001b[39mtime,\n\u001b[0;32m    180\u001b[0m         forward_func\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattribution_method\u001b[39m.\u001b[39mforward_func,\n\u001b[0;32m    181\u001b[0m         task\u001b[39m=\u001b[39mtask,\n\u001b[0;32m    182\u001b[0m         threshold\u001b[39m=\u001b[39mthreshold,\n\u001b[0;32m    183\u001b[0m         temporal_target\u001b[39m=\u001b[39mtemporal_target,\n\u001b[0;32m    184\u001b[0m         temporal_additional_forward_args\u001b[39m=\u001b[39mtemporal_additional_forward_args,\n\u001b[0;32m    185\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    188\u001b[0m     \u001b[39m# Get partial targets\u001b[39;00m\n\u001b[0;32m    189\u001b[0m     partial_targets \u001b[39m=\u001b[39m kwargs_copy\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tint\\utils\\common.py:151\u001b[0m, in \u001b[0;36m_slice_to_time\u001b[1;34m(inputs, time, forward_func, task, threshold, temporal_target, temporal_additional_forward_args, *args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     additional_forward_args \u001b[39m=\u001b[39m kwargs_copy[\u001b[39m\"\u001b[39m\u001b[39madditional_forward_args\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    149\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    150\u001b[0m     \u001b[39m# Get model outputs\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m     partial_targets \u001b[39m=\u001b[39m _run_forward(\n\u001b[0;32m    152\u001b[0m         forward_func,\n\u001b[0;32m    153\u001b[0m         partial_inputs,\n\u001b[0;32m    154\u001b[0m         additional_forward_args\u001b[39m=\u001b[39;49madditional_forward_args,\n\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    157\u001b[0m \u001b[39m# Get target as predictions\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[39mif\u001b[39;00m task \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\captum\\_utils\\common.py:482\u001b[0m, in \u001b[0;36m_run_forward\u001b[1;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[0;32m    479\u001b[0m inputs \u001b[39m=\u001b[39m _format_inputs(inputs)\n\u001b[0;32m    480\u001b[0m additional_forward_args \u001b[39m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m--> 482\u001b[0m output \u001b[39m=\u001b[39m forward_func(\n\u001b[0;32m    483\u001b[0m     \u001b[39m*\u001b[39;49m(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49madditional_forward_args)\n\u001b[0;32m    484\u001b[0m     \u001b[39mif\u001b[39;49;00m additional_forward_args \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m    485\u001b[0m     \u001b[39melse\u001b[39;49;00m inputs\n\u001b[0;32m    486\u001b[0m )\n\u001b[0;32m    487\u001b[0m \u001b[39mreturn\u001b[39;00m _select_targets(output, target)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Softwares\\SA-Timeseries\\models\\Autoformer.py:147\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x_enc, x_mark_enc, x_dec, x_mark_dec, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    146\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlong_term_forecast\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mshort_term_forecast\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 147\u001b[0m         dec_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n\u001b[0;32m    148\u001b[0m         f_dim \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfigs\u001b[39m.\u001b[39mfeatures \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMS\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39mreturn\u001b[39;00m dec_out[:, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_len:, f_dim:]  \u001b[39m# [B, L, D]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Softwares\\SA-Timeseries\\models\\Autoformer.py:106\u001b[0m, in \u001b[0;36mModel.forecast\u001b[1;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec)\u001b[0m\n\u001b[0;32m    104\u001b[0m enc_out, attns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(enc_out, attn_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m \u001b[39m# dec\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m dec_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdec_embedding(seasonal_init, x_mark_dec)\n\u001b[0;32m    107\u001b[0m seasonal_part, trend_part \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(dec_out, enc_out, x_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cross_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    108\u001b[0m                                          trend\u001b[39m=\u001b[39mtrend_init)\n\u001b[0;32m    109\u001b[0m \u001b[39m# final\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Softwares\\SA-Timeseries\\layers\\Embed.py:144\u001b[0m, in \u001b[0;36mDataEmbedding_wo_pos.forward\u001b[1;34m(self, x, x_mark)\u001b[0m\n\u001b[0;32m    142\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_embedding(x)\n\u001b[0;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_embedding(x) \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemporal_embedding(x_mark)\n\u001b[0;32m    145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (25) must match the size of tensor b (36) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "explainer = TimeForwardTunnel(GradientShap(model))\n",
    "attr = explainer.attribute(\n",
    "    inputs=batch_x, \n",
    "    baselines=0,\n",
    "    n_samples=50, stdevs = 0.0001, return_temporal_attributions=True,\n",
    "    task='regression', \n",
    "    additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intergrated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Local\\Temp\\ipykernel_6104\\2489629731.py\", line 2, in <cell line: 2>\n",
      "    attr = explainer.attribute(\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\captum\\log\\__init__.py\", line 42, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\tint\\attr\\time_forward_tunnel.py\", line 202, in attribute\n",
      "    ) = self.compute_partial_attribution(\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\tint\\attr\\time_forward_tunnel.py\", line 284, in compute_partial_attribution\n",
      "    attributions = self.attribution_method.attribute.__wrapped__(\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\captum\\attr\\_core\\integrated_gradients.py\", line 286, in attribute\n",
      "    attributions = self._attribute(\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\captum\\attr\\_core\\integrated_gradients.py\", line 351, in _attribute\n",
      "    grads = self.gradient_func(\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\captum\\_utils\\gradient.py\", line 112, in compute_gradients\n",
      "    outputs = _run_forward(forward_fn, inputs, target_ind, additional_forward_args)\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\captum\\_utils\\common.py\", line 482, in _run_forward\n",
      "    output = forward_func(\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Softwares\\SA-Timeseries\\models\\MICN.py\", line 221, in forward\n",
      "    f_dim = -1 if self.configs.features == 'MS' else 0\n",
      "  File \"c:\\Softwares\\SA-Timeseries\\models\\MICN.py\", line 171, in forecast\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (11200x1 and 36x24)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 1993, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "explainer = TimeForwardTunnel(IntegratedGradients(model))\n",
    "attr = explainer.attribute(\n",
    "    inputs=inputs, target=0,\n",
    "    additional_forward_args=additional_forward_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GradientShap.attribute() got an unexpected keyword argument 'draw_baseline_from_distrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Softwares\\SA-Timeseries\\dual_interpret.ipynb Cell 28\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m explainer \u001b[39m=\u001b[39m GradientShap(model)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m attr \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mattribute(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     inputs\u001b[39m=\u001b[39;49minputs, baselines\u001b[39m=\u001b[39;49mget_baseline(inputs),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     additional_forward_args\u001b[39m=\u001b[39;49madditional_forward_args, draw_baseline_from_distrib\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Softwares/SA-Timeseries/dual_interpret.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\captum\\log\\__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: GradientShap.attribute() got an unexpected keyword argument 'draw_baseline_from_distrib'"
     ]
    }
   ],
   "source": [
    "explainer = GradientShap(model)\n",
    "attr = explainer.attribute(\n",
    "    inputs=inputs, target=0, baselines=get_baseline(inputs),\n",
    "    additional_forward_args=additional_forward_args, draw_baseline_from_distrib=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commented out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_error = mse(\n",
    "#     model, inputs=batch_x, \n",
    "#     attributions=temp, baselines=0, \n",
    "#     additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark),\n",
    "#     topk=0.2\n",
    "# )\n",
    "# print(mse_error)\n",
    "\n",
    "# mae_error = mae(\n",
    "#     model, inputs=batch_x, \n",
    "#     attributions=temp, baselines=0, \n",
    "#     additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark),\n",
    "#     # target=0,\n",
    "#     topk=0.2\n",
    "# )\n",
    "# print(mae_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal_mask = torch.zeros_like(batch_x, dtype=int)\n",
    "# for t in range(batch_x.shape[1]):\n",
    "#     temporal_mask[:, t] = t\n",
    "\n",
    "# explainer = FeatureAblation(model)\n",
    "# time_score = explainer.attribute(\n",
    "#     inputs=(batch_x),\n",
    "#     baselines=(batch_x*0),\n",
    "#     additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark),\n",
    "#     target=0,\n",
    "#     feature_mask=temporal_mask\n",
    "# )\n",
    "# print(score.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
