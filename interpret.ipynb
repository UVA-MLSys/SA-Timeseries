{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import *\n",
    "from tint.metrics import mse, mae\n",
    "import tint, gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.explainer import *\n",
    "from utils.tsr_tunnel import TSRTunnel\n",
    "from exp.exp_interpret import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import (\n",
    "    DeepLift,\n",
    "    GradientShap,\n",
    "    IntegratedGradients,\n",
    "    Lime\n",
    ")\n",
    "\n",
    "from tint.attr import (\n",
    "    AugmentedOcclusion,\n",
    "    DynaMask, Fit,\n",
    "    Occlusion, \n",
    "    FeatureAblation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser()\n",
    "argv = \"\"\"\n",
    "  --task_name long_term_forecast \\\n",
    "  --use_gpu \\\n",
    "  --result_path scratch \\\n",
    "  --root_path ./dataset/illness/ \\\n",
    "  --data_path national_illness.csv \\\n",
    "  --model LSTM \\\n",
    "  --features MS \\\n",
    "  --seq_len 36 \\\n",
    "  --label_len 12 \\\n",
    "  --pred_len 24 \\\n",
    "  --n_features 7\n",
    "\"\"\".split()\n",
    "args = parser.parse_args(argv)\n",
    "\n",
    "# Disable cudnn if using cuda accelerator.\n",
    "# Please see https://captum.ai/docs/faq#how-can-i-resolve-cudnn-rnn-backward-error-for-rnn-or-lstm-network\n",
    "# args.use_gpu = False\n",
    "initial_setup(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Experiments will be saved in scratch\\national_illness_LSTM\n",
      "test 73\n",
      "Loading model from scratch\\national_illness_LSTM\\checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "if args.task_name == 'classification': Exp = Exp_Classification\n",
    "else: Exp = Exp_Long_Term_Forecast\n",
    "exp = Exp(args)  # set experiments\n",
    "_, dataloader = exp._get_data(args.flag)\n",
    "\n",
    "exp.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp.model\n",
    "model.eval()\n",
    "\n",
    "# only need to output targets, sinec interpretation is based on outputs\n",
    "assert not exp.args.output_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_metric_map = {\n",
    "    'mae': mae, 'mse': mse\n",
    "}\n",
    "areas = [0.03, 0.05, 0.1, 0.2]\n",
    "\n",
    "explainers = ['deep_lift', 'feature_ablation'] # explainers = args.explainers\n",
    "explainers_map = dict()\n",
    "for name in explainers:\n",
    "    explainers_map[name] = explainer_name_map[name](model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# \"zero\", \"aug\", \"random\"\n",
    "# performance order random > zero > aug\n",
    "baseline_mode = \"random\" \n",
    "\n",
    "result_columns = ['batch_index', 'explainer', 'metric', 'area', 'comp', 'suff']\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    enumerate(dataloader), total=len(dataloader), disable=False\n",
    ")\n",
    "for batch_index, (batch_x, batch_y, batch_x_mark, batch_y_mark) in progress_bar:\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()\n",
    "    # outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    \n",
    "    # baseline must be a scaler or tuple of tensors with same dimension as input\n",
    "    baselines = get_baseline(batch_x, mode=baseline_mode)\n",
    "    additional_forward_args = (batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "    # get attributions\n",
    "    for name in explainers:\n",
    "        explainer = explainers_map[name]\n",
    "        attr = compute_regressor_attr(\n",
    "            batch_x, baselines, explainer, additional_forward_args, args\n",
    "        )\n",
    "    \n",
    "        # get scores\n",
    "        for area in areas:\n",
    "            for metric_name, metric in expl_metric_map.items():\n",
    "                error_comp = metric(\n",
    "                    model, inputs=batch_x, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=True\n",
    "                )\n",
    "                \n",
    "                error_suff = metric(\n",
    "                    model, inputs=batch_x, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=False\n",
    "                )\n",
    "           \n",
    "                result_row = [batch_index, name, metric_name, area, error_comp, error_suff]\n",
    "                results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y, batch_x_mark, batch_y_mark = next(iter(dataloader))\n",
    "batch_x = batch_x.float().to(exp.device)\n",
    "batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "# decoder input\n",
    "dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = get_total_data(dataloader, exp.device)\n",
    "inputs = (batch_x, batch_x_mark)\n",
    "additional_forward_args = (dec_inp, batch_y_mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = (batch_x, batch_x_mark)\n",
    "additional_forward_args = (dec_inp, batch_y_mark)\n",
    "explainer = FeatureAblation(exp.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = explainer.attribute(\n",
    "    inputs=inputs, baselines=(0,0),\n",
    "    additional_forward_args=additional_forward_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal_mask = torch.zeros_like(batch_x, dtype=int)\n",
    "# for t in range(batch_x.shape[1]):\n",
    "#     temporal_mask[:, t] = t\n",
    "\n",
    "# explainer = FeatureAblation(model)\n",
    "# time_score = explainer.attribute(\n",
    "#     inputs=(batch_x),\n",
    "#     baselines=(batch_x*0),\n",
    "#     additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark),\n",
    "#     target=0,\n",
    "#     feature_mask=temporal_mask\n",
    "# )\n",
    "# print(score.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
