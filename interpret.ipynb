{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import *\n",
    "from tint.metrics import mse, mae\n",
    "import tint, gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.explainer import *\n",
    "from utils.explainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import (\n",
    "    DeepLift,\n",
    "    GradientShap,\n",
    "    IntegratedGradients,\n",
    "    Lime\n",
    ")\n",
    "\n",
    "from tint.attr import (\n",
    "    AugmentedOcclusion,\n",
    "    DynaMask,\n",
    "    Occlusion, \n",
    "    FeatureAblation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser()\n",
    "argv = \"\"\"\n",
    "  --root_path ./dataset/illness/ \\\n",
    "  --data_path national_illness.csv \\\n",
    "  --model_id ili_36_24 \\\n",
    "  --model Transformer \\\n",
    "  --data custom \\\n",
    "    --use_gpu\n",
    "  --features MS \\\n",
    "  --seq_len 36 \\\n",
    "  --label_len 18 \\\n",
    "  --pred_len 24 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des Exp \\\n",
    "  --itr 1\n",
    "\"\"\".split()\n",
    "args = parser.parse_args(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.explainers = [\n",
    "    \"deep_lift\",\n",
    "    \"gradient_shap\",\n",
    "    \"integrated_gradients\",\n",
    "    \"lime\",\n",
    "    \"occlusion\",\n",
    "    \"augmented_occlusion\",\n",
    "    \"dyna_mask\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_name_map = {\"deep_lift\":DeepLift,\n",
    "    \"gradient_shap\":GradientShap,\n",
    "    \"integrated_gradients\":IntegratedGradients,\n",
    "    \"lime\":Lime,\n",
    "    \"occlusion\":Occlusion,\n",
    "    # \"augmented_occlusion\":AugmentedOcclusion,\n",
    "    \"dyna_mask\":DynaMask,\n",
    "    \"feature_ablation\":FeatureAblation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(args.seed)\n",
    "# Disable cudnn if using cuda accelerator.\n",
    "# Please see https://captum.ai/docs/faq#how-can-i-resolve-cudnn-rnn-backward-error-for-rnn-or-lstm-network\n",
    "# args.use_gpu = False\n",
    "\n",
    "assert args.task_name == 'long_term_forecast', \"Only long_term_forecast is supported for now\"\n",
    "Exp = Exp_Long_Term_Forecast\n",
    "\n",
    "setting = stringify_setting(args, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Exp(args)  # set experiments\n",
    "_, dataloader = exp._get_data('test')\n",
    "exp.model.load_state_dict(\n",
    "    torch.load(os.path.join('checkpoints/' + setting, 'checkpoint.pth'))\n",
    ")\n",
    "result_folder = './results/' + setting + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp.model\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# only need to output targets, sinec interpretation is based on outputs\n",
    "assert not exp.args.output_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_metric_map = {\n",
    "    'mae': mae, 'mse': mse\n",
    "}\n",
    "areas = [0.1, 0.2, 0.5]\n",
    "\n",
    "explainers = ['deep_lift', 'feature_ablation'] # explainers = args.explainers\n",
    "explainers_map = dict()\n",
    "for name in explainers:\n",
    "    explainers_map[name] = explainer_name_map[name](model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "baseline_mode = \"aug\" # \"zeros\", \"aug\"\n",
    "result_columns = ['batch_index', 'explainer', 'metric', 'area', 'comp', 'suff']\n",
    "output_file = open(os.path.join(result_folder, \"batch_interpretation_results.csv\"), 'w')\n",
    "output_file.write(','.join(result_columns))\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    enumerate(dataloader), total=len(dataloader), disable=False\n",
    ")\n",
    "for batch_index, (batch_x, batch_y, batch_x_mark, batch_y_mark) in progress_bar:\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()\n",
    "    # outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    \n",
    "    inputs = batch_x\n",
    "    # baseline must be a scaler or tuple of tensors with same dimension as input\n",
    "    if baseline_mode=='zeros': baselines = torch.zeros_like(inputs)\n",
    "    else: baselines = torch.mean(inputs, axis=0).repeat(inputs.shape[0], 1, 1).float()\n",
    "    additional_forward_args = (batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "    # get attributions\n",
    "    for name in explainers:\n",
    "        explainer = explainers_map[name]\n",
    "        attr = compute_attr(\n",
    "            inputs, baselines, explainer, additional_forward_args, args\n",
    "        )\n",
    "    \n",
    "        # get scores\n",
    "        for area in areas:\n",
    "            for metric_name, metric in expl_metric_map.items():\n",
    "                error_comp = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=True\n",
    "                )\n",
    "                \n",
    "                error_suff = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=False\n",
    "                )\n",
    "           \n",
    "                result_row = [batch_index, name, metric_name, area, error_comp, error_suff]\n",
    "                # print(result_row)\n",
    "                output_file.write(\"\\n\" + ','.join([str(r) for r in result_row]))\n",
    "                results.append(result_row)\n",
    "        \n",
    "        output_file.flush()\n",
    "    # break\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=result_columns)\n",
    "results_df = results_df.groupby(['explainer', 'metric', 'area'])[['comp', 'suff']].aggregate('mean').reset_index()\n",
    "results_df.round(6).to_csv(os.path.join(result_folder, 'interpretation_results.csv'), index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "baseline_mode = \"aug\" # \"zeros\", \"aug\"\n",
    "result_columns = ['batch_index', 'explainer', 'metric', 'area', 'comp', 'suff']\n",
    "output_file = open(os.path.join(result_folder, \"batch_interpretation_results_tsr.csv\"), 'w')\n",
    "output_file.write(','.join(result_columns))\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    enumerate(dataloader), total=len(dataloader), disable=False\n",
    ")\n",
    "for batch_index, (batch_x, batch_y, batch_x_mark, batch_y_mark) in progress_bar:\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()\n",
    "    # outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    \n",
    "    inputs = batch_x\n",
    "    # baseline must be a scaler or tuple of tensors with same dimension as input\n",
    "    if baseline_mode=='zeros': baselines = torch.zeros_like(inputs)\n",
    "    else: baselines = torch.mean(inputs, axis=0).repeat(inputs.shape[0], 1, 1).float()\n",
    "    additional_forward_args = (batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "    # get attributions\n",
    "    for name in explainers:\n",
    "        explainer = explainers_map[name]\n",
    "        attr = compute_tsr_attr(\n",
    "            inputs, baselines, explainer, additional_forward_args, args\n",
    "        )\n",
    "    \n",
    "        # get scores\n",
    "        for area in areas:\n",
    "            for metric_name, metric in expl_metric_map.items():\n",
    "                error_comp = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=True\n",
    "                )\n",
    "                \n",
    "                error_suff = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=False\n",
    "                )\n",
    "           \n",
    "                result_row = [batch_index, name, metric_name, area, error_comp, error_suff]\n",
    "                # print(result_row)\n",
    "                output_file.write(\"\\n\" + ','.join([str(r) for r in result_row]))\n",
    "                results.append(result_row)\n",
    "        \n",
    "        output_file.flush()\n",
    "    # break\n",
    "    gc.collect()\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsr_results_df = pd.DataFrame(results, columns=result_columns)\n",
    "tsr_results_df = tsr_results_df.groupby(['explainer', 'metric', 'area'])[['comp', 'suff']].aggregate('mean').reset_index()\n",
    "tsr_results_df.round(6).to_csv(os.path.join(result_folder, 'interpretation_results_tsr.csv'), index=False)\n",
    "print(tsr_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = FeatureAblation(model)\n",
    "actual_attr = compute_attr(inputs, baselines, explainer, additional_forward_args, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch x seq_len\n",
    "time_attr = torch.zeros((inputs.shape[0], args.seq_len), dtype=float)\n",
    "\n",
    "for t in tqdm(range(args.seq_len)):\n",
    "    new_inputs = inputs.clone() \n",
    "    # batch x seq_len x features\n",
    "    new_inputs[:, t] = 0 # test with new_inputs[:, :t+1] and other mastking\n",
    "\n",
    "    new_attr_per_time = compute_attr(\n",
    "        new_inputs, baselines, explainer, \n",
    "        additional_forward_args, args\n",
    "    )\n",
    "    \n",
    "    # sum the attr difference for each input in the batch\n",
    "    # batch x seq_len x features -> batch\n",
    "    time_attr[:, t] = (actual_attr - new_attr_per_time\n",
    "        ).abs().sum(axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each input in the batch, normalize along the time axis\n",
    "time_attr = torch.nn.functional.normalize(time_attr, p=1, dim=1)\n",
    "# find median along the time axis\n",
    "mean_time_importance = np.quantile(time_attr, .55, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = inputs.shape[-1]\n",
    "input_attr = torch.zeros((inputs.shape[0], n_features), dtype=float)\n",
    "time_scaled_attr = torch.zeros_like(actual_attr)\n",
    "\n",
    "for t in tqdm(range(args.seq_len)):\n",
    "    # if time_attr[t] < mean_time_importance:\n",
    "    #     featureContibution = torch.ones(input_attr, dtype=float)/n_features\n",
    "    for f in range(n_features):\n",
    "        new_inputs = inputs.clone() # batch x seq_len x features\n",
    "        new_inputs[:, t, f] = 0\n",
    "        \n",
    "        attr = compute_attr(\n",
    "            new_inputs, baselines, explainer, \n",
    "            additional_forward_args, args\n",
    "        )\n",
    "        input_attr[:, f] = (actual_attr - attr).abs().sum(axis=(1, 2))\n",
    "    \n",
    "    input_attr = torch.nn.functional.normalize(input_attr, p=1, dim=1)\n",
    "    \n",
    "    for f in range(n_features):\n",
    "        time_scaled_attr[:, t, f] = time_attr[:, t] * input_attr[:, f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "name = 'feature_ablation'\n",
    "for area in areas:\n",
    "    for metric_name in ['mae', 'mse']:\n",
    "        metric = getattr(tint.metrics, metric_name)\n",
    "        error_comp = metric(\n",
    "            model, inputs=inputs, \n",
    "            attributions=time_scaled_attr, baselines=baselines, \n",
    "            additional_forward_args=additional_forward_args,\n",
    "            topk=area, mask_largest=True\n",
    "        )\n",
    "\n",
    "        error_suff = metric(\n",
    "            model, inputs=inputs, \n",
    "            attributions=time_scaled_attr, baselines=baselines, \n",
    "            additional_forward_args=additional_forward_args,\n",
    "            topk=area, mask_largest=False\n",
    "        )\n",
    "        result_row = [0, name, metric_name, area, error_comp, error_suff]\n",
    "        results.append(result_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsr_results_df = pd.DataFrame(results, columns=result_columns)\n",
    "tsr_results_df = tsr_results_df.groupby(['explainer', 'metric', 'area'])[['comp', 'suff']].aggregate('mean').reset_index()\n",
    "# results_df.round(6).to_csv(os.path.join(result_folder, 'interpretation_results.csv'), index=False)\n",
    "print(tsr_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['explainer']=='feature_ablation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.get_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Occlusion(model)\n",
    "scores = explainer.attribute(\n",
    "    inputs=inputs, baselines=baselines, sliding_window_shapes = (1,1),\n",
    "    additional_forward_args=additional_forward_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_error = mae(\n",
    "    model, inputs=inputs, \n",
    "    attributions=attr, baselines=baselines, \n",
    "    additional_forward_args=additional_forward_args,\n",
    "    topk=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal_mask = torch.zeros_like(batch_x, dtype=int)\n",
    "# for t in range(batch_x.shape[1]):\n",
    "#     temporal_mask[:, t] = t\n",
    "\n",
    "# explainer = FeatureAblation(model)\n",
    "# time_score = explainer.attribute(\n",
    "#     inputs=(batch_x),\n",
    "#     baselines=(batch_x*0),\n",
    "#     additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark),\n",
    "#     target=0,\n",
    "#     feature_mask=temporal_mask\n",
    "# )\n",
    "# print(score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tint.attr import Occlusion\n",
    "\n",
    "# temporal_mask = torch.zeros(size=(1, *batch_x.shape[1:]), dtype=int)\n",
    "# for t in range(batch_x.shape[1]):\n",
    "#     temporal_mask[:, t, :] = t\n",
    "\n",
    "# explainer = Occlusion(model)\n",
    "# time_score = explainer.attribute(\n",
    "#     inputs=(batch_x),\n",
    "#     baselines=(batch_x*0),\n",
    "#     additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark),\n",
    "#     sliding_window_shapes=(1, 1)\n",
    "#     # feature_mask=temporal_mask.to(exp.device)\n",
    "# )\n",
    "# print(time_score.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
