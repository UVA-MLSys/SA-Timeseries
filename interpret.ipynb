{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import *\n",
    "from tint.metrics import mse, mae\n",
    "import tint, gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.explainer import *\n",
    "from exp.exp_interpret import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import (\n",
    "    DeepLift,\n",
    "    GradientShap,\n",
    "    IntegratedGradients,\n",
    "    Lime\n",
    ")\n",
    "\n",
    "from tint.attr import (\n",
    "    AugmentedOcclusion,\n",
    "    DynaMask,\n",
    "    Occlusion, \n",
    "    FeatureAblation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser()\n",
    "argv = \"\"\"\n",
    "  --task_name long_term_forecast \\\n",
    "  --use_gpu \\\n",
    "  --root_path ./dataset/illness/ \\\n",
    "  --data_path national_illness.csv \\\n",
    "  --model Autoformer \\\n",
    "  --features MS \\\n",
    "  --seq_len 36 \\\n",
    "  --label_len 12 \\\n",
    "  --pred_len 24 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 --batch_size 16\n",
    "\"\"\".split()\n",
    "args = parser.parse_args(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_name_map = {\n",
    "    \"deep_lift\":DeepLift,\n",
    "    \"gradient_shap\":GradientShap,\n",
    "    \"integrated_gradients\":IntegratedGradients,\n",
    "    \"lime\":Lime,\n",
    "    \"occlusion\":Occlusion,\n",
    "    # \"augmented_occlusion\":AugmentedOcclusion,\n",
    "    \"dyna_mask\":DynaMask,\n",
    "    \"feature_ablation\":FeatureAblation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(args.seed)\n",
    "# Disable cudnn if using cuda accelerator.\n",
    "# Please see https://captum.ai/docs/faq#how-can-i-resolve-cudnn-rnn-backward-error-for-rnn-or-lstm-network\n",
    "# args.use_gpu = False\n",
    "\n",
    "assert args.task_name == 'long_term_forecast', \"Only long_term_forecast is supported for now\"\n",
    "Exp = Exp_Long_Term_Forecast\n",
    "\n",
    "setting = stringify_setting(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)  # set experiments\n",
    "exp.model.load_state_dict(\n",
    "    torch.load(os.path.join('checkpoints/' + setting, 'checkpoint.pth'))\n",
    ")\n",
    "result_folder = './results/' + setting + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp.model\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# only need to output targets, sinec interpretation is based on outputs\n",
    "assert not exp.args.output_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 73\n"
     ]
    }
   ],
   "source": [
    "flag = 'test'\n",
    "_, dataloader = exp._get_data(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_metric_map = {\n",
    "    'mae': mae, 'mse': mse\n",
    "}\n",
    "areas = [0.03, 0.05, 0.1, 0.2]\n",
    "\n",
    "explainers = ['deep_lift', 'feature_ablation'] # explainers = args.explainers\n",
    "explainers_map = dict()\n",
    "for name in explainers:\n",
    "    explainers_map[name] = explainer_name_map[name](model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# \"zero\", \"aug\", \"random\"\n",
    "# performance order random > zero > aug\n",
    "baseline_mode = \"random\" \n",
    "\n",
    "result_columns = ['batch_index', 'explainer', 'metric', 'area', 'comp', 'suff']\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    enumerate(dataloader), total=len(dataloader), disable=False\n",
    ")\n",
    "for batch_index, (batch_x, batch_y, batch_x_mark, batch_y_mark) in progress_bar:\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()\n",
    "    # outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    \n",
    "    inputs = batch_x\n",
    "    # baseline must be a scaler or tuple of tensors with same dimension as input\n",
    "    if baseline_mode=='zero': baselines = torch.zeros_like(inputs)\n",
    "    elif baseline_mode == 'random': baselines = torch.randn_like(inputs)\n",
    "    else: baselines = torch.mean(inputs, axis=0).repeat(inputs.shape[0], 1, 1).float()\n",
    "    additional_forward_args = (batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "    # get attributions\n",
    "    for name in explainers:\n",
    "        explainer = explainers_map[name]\n",
    "        attr = compute_attr(\n",
    "            inputs, baselines, explainer, additional_forward_args, args\n",
    "        )\n",
    "    \n",
    "        # get scores\n",
    "        for area in areas:\n",
    "            for metric_name, metric in expl_metric_map.items():\n",
    "                error_comp = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=True\n",
    "                )\n",
    "                \n",
    "                error_suff = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=False\n",
    "                )\n",
    "           \n",
    "                result_row = [batch_index, name, metric_name, area, error_comp, error_suff]\n",
    "                results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           explainer metric  area        comp        suff\n",
      "0          deep_lift    mae  0.03   22.387512   47.552436\n",
      "1          deep_lift    mae  0.05   35.472929   34.969124\n",
      "2          deep_lift    mae  0.10   62.132083   12.359752\n",
      "3          deep_lift    mae  0.20   80.801300   15.408948\n",
      "4          deep_lift    mse  0.03   22.275765  100.830368\n",
      "5          deep_lift    mse  0.05   54.752081   56.914517\n",
      "6          deep_lift    mse  0.10  165.784731    9.525279\n",
      "7          deep_lift    mse  0.20  286.879962   17.974950\n",
      "8   feature_ablation    mae  0.03   22.090495   48.157625\n",
      "9   feature_ablation    mae  0.05   34.997378   35.562492\n",
      "10  feature_ablation    mae  0.10   61.651758   12.793189\n",
      "11  feature_ablation    mae  0.20   79.969749   13.870515\n",
      "12  feature_ablation    mse  0.03   21.877092  102.763078\n",
      "13  feature_ablation    mse  0.05   53.530500   58.256120\n",
      "14  feature_ablation    mse  0.10  163.161661   10.077021\n",
      "15  feature_ablation    mse  0.20  279.247916   15.032560\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=result_columns)\n",
    "results_df = results_df.groupby(['explainer', 'metric', 'area'])[['comp', 'suff']].aggregate('mean').reset_index()\n",
    "# results_df.round(6).to_csv(os.path.join(result_folder, 'interpretation_results.csv'), index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tsr_attr(\n",
    "    inputs, baselines, explainer, additional_forward_args, args, device, masking='point'\n",
    "):\n",
    "    actual_attr = compute_attr(inputs, baselines, explainer, additional_forward_args, args)\n",
    "    # batch x seq_len\n",
    "    time_attr = torch.zeros((inputs.shape[0], args.seq_len), dtype=float, device=device)\n",
    "    new_inputs = inputs.clone() \n",
    "    \n",
    "    assignment = torch.randn_like(new_inputs)\n",
    "    for t in range(args.seq_len):\n",
    "        if masking == 'point':\n",
    "            prev_value = new_inputs[:, t]\n",
    "            # batch x seq_len x features\n",
    "            new_inputs[:, t] = assignment[:, t] # assignment # inputs[0, 0, -1] # test with new_inputs[:, :t+1] and other masking\n",
    "        else:\n",
    "            prev_value = new_inputs[:, :t]\n",
    "            # batch x seq_len x features\n",
    "            new_inputs[:, :t] = assignment[:, :t]\n",
    "\n",
    "        new_attr_per_time = compute_attr(\n",
    "            new_inputs, baselines, explainer, \n",
    "            additional_forward_args, args\n",
    "        )\n",
    "        \n",
    "        # sum the attr difference for each input in the batch\n",
    "        # batch x seq_len x features -> batch\n",
    "        time_attr[:, t] = (actual_attr - new_attr_per_time\n",
    "            ).abs().sum(axis=(1, 2))\n",
    "        \n",
    "        if masking == 'point':\n",
    "            new_inputs[:, t] = prev_value\n",
    "        else:\n",
    "            new_inputs[:, :t] = prev_value\n",
    "    \n",
    "    # for each input in the batch, normalize along the time axis\n",
    "    time_attr = min_max_scale(time_attr, dim=1)\n",
    "    \n",
    "    # new_attr = (time_attr.T * actual_attr.T).T\n",
    "    # return new_attr\n",
    "\n",
    "    # find median along the time axis\n",
    "    # mean_time_importance = np.quantile(time_attr, .55, axis=1)   \n",
    "    \n",
    "    n_features = inputs.shape[-1]\n",
    "    input_attr = torch.zeros((inputs.shape[0], n_features), dtype=float, device=device)\n",
    "    time_scaled_attr = torch.zeros_like(actual_attr)\n",
    "\n",
    "    assignment = torch.randn((inputs.shape[0],inputs.shape[1]), dtype=float)\n",
    "    for t in range(args.seq_len):\n",
    "        # if time_attr[t] < mean_time_importance:\n",
    "        #     featureContibution = torch.ones(input_attr, dtype=float)/n_features\n",
    "        for f in range(n_features):\n",
    "             # batch x seq_len x features\n",
    "            if masking == 'point':\n",
    "                prev_value = new_inputs[:, t, f]\n",
    "                new_inputs[:, t, f] = assignment[:, t] # inputs[0, 0, f] # assignment[:, f] # inputs[0, 0, f]\n",
    "            else:\n",
    "                prev_value = new_inputs[:, :t, f]\n",
    "                new_inputs[:, :t, f] = assignment[:, :t]\n",
    "            \n",
    "            attr = compute_attr(\n",
    "                new_inputs, baselines, explainer, \n",
    "                additional_forward_args, args\n",
    "            )\n",
    "            input_attr[:, f] = (actual_attr - attr).abs().sum(axis=(1, 2))\n",
    "            if masking == 'point':\n",
    "                new_inputs[:, t, f] = prev_value\n",
    "            else:\n",
    "                new_inputs[:, :t, f] = prev_value\n",
    "        \n",
    "        input_attr = min_max_scale(input_attr, dim=1)\n",
    "        \n",
    "        for f in range(n_features):\n",
    "            time_scaled_attr[:, t, f] = time_attr[:, t] * input_attr[:, f]\n",
    "            \n",
    "    return time_scaled_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "baseline_mode = 'random'\n",
    "result_columns = ['batch_index', 'explainer', 'metric', 'area', 'comp', 'suff']\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    enumerate(dataloader), total=len(dataloader), disable=False\n",
    ")\n",
    "for batch_index, (batch_x, batch_y, batch_x_mark, batch_y_mark) in progress_bar:\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()\n",
    "    # outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    \n",
    "    inputs = batch_x\n",
    "    # baseline must be a scaler or tuple of tensors with same dimension as input\n",
    "    if baseline_mode=='zeros': baselines = torch.zeros_like(inputs)\n",
    "    elif baseline_mode == 'random': baselines = torch.randn_like(inputs)\n",
    "    else: baselines = torch.mean(inputs, axis=0).repeat(inputs.shape[0], 1, 1).float()\n",
    "    additional_forward_args = (batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "    # get attributions\n",
    "    for name in explainers:\n",
    "        explainer = explainers_map[name]\n",
    "        attr = compute_tsr_attr(\n",
    "            inputs, baselines, explainer, additional_forward_args, args, exp.device\n",
    "        )\n",
    "    \n",
    "        # get scores\n",
    "        for area in areas:\n",
    "            for metric_name, metric in expl_metric_map.items():\n",
    "                error_comp = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=True\n",
    "                )\n",
    "                \n",
    "                error_suff = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=False\n",
    "                )\n",
    "           \n",
    "                result_row = [batch_index, name, metric_name, area, error_comp, error_suff]\n",
    "                results.append(result_row)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsr_results_df = pd.DataFrame(results, columns=result_columns)\n",
    "tsr_results_df = tsr_results_df.groupby(['explainer', 'metric', 'area'])[['comp', 'suff']].aggregate('mean').reset_index()\n",
    "tsr_results_df.round(6).to_csv(os.path.join(result_folder, 'interpretation_results_tsr.csv'), index=False)\n",
    "print(tsr_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = Occlusion(model)\n",
    "# scores = explainer.attribute(\n",
    "#     inputs=inputs, baselines=baselines, sliding_window_shapes = (1,1),\n",
    "#     additional_forward_args=additional_forward_args\n",
    "# )\n",
    "# mae_error = mae(\n",
    "#     model, inputs=inputs, \n",
    "#     attributions=attr, baselines=baselines, \n",
    "#     additional_forward_args=additional_forward_args,\n",
    "#     topk=0.2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal_mask = torch.zeros_like(batch_x, dtype=int)\n",
    "# for t in range(batch_x.shape[1]):\n",
    "#     temporal_mask[:, t] = t\n",
    "\n",
    "# explainer = FeatureAblation(model)\n",
    "# time_score = explainer.attribute(\n",
    "#     inputs=(batch_x),\n",
    "#     baselines=(batch_x*0),\n",
    "#     additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark),\n",
    "#     target=0,\n",
    "#     feature_mask=temporal_mask\n",
    "# )\n",
    "# print(score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tint.attr import Occlusion\n",
    "\n",
    "# temporal_mask = torch.zeros(size=(1, *batch_x.shape[1:]), dtype=int)\n",
    "# for t in range(batch_x.shape[1]):\n",
    "#     temporal_mask[:, t, :] = t\n",
    "\n",
    "# explainer = Occlusion(model)\n",
    "# time_score = explainer.attribute(\n",
    "#     inputs=(batch_x),\n",
    "#     baselines=(batch_x*0),\n",
    "#     additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark),\n",
    "#     sliding_window_shapes=(1, 1)\n",
    "#     # feature_mask=temporal_mask.to(exp.device)\n",
    "# )\n",
    "# print(time_score.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
