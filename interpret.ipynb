{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import *\n",
    "from tint.metrics import mse, mae\n",
    "import tint, gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.explainer import *\n",
    "from utils.tsr_tunnel import TSRTunnel\n",
    "from exp.exp_interpret import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import (\n",
    "    DeepLift,\n",
    "    GradientShap,\n",
    "    IntegratedGradients,\n",
    "    Lime\n",
    ")\n",
    "\n",
    "from tint.attr import (\n",
    "    AugmentedOcclusion,\n",
    "    DynaMask,\n",
    "    Occlusion, \n",
    "    FeatureAblation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser()\n",
    "argv = \"\"\"\n",
    "  --task_name long_term_forecast \\\n",
    "  --use_gpu \\\n",
    "  --root_path ./dataset/illness/ \\\n",
    "  --data_path national_illness.csv \\\n",
    "  --model Autoformer \\\n",
    "  --features MS \\\n",
    "  --seq_len 36 \\\n",
    "  --label_len 12 \\\n",
    "  --pred_len 24 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 --batch_size 16\n",
    "\"\"\".split()\n",
    "args = parser.parse_args(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_name_map = {\n",
    "    \"deep_lift\":DeepLift,\n",
    "    \"gradient_shap\":GradientShap,\n",
    "    \"integrated_gradients\":IntegratedGradients,\n",
    "    \"lime\":Lime,\n",
    "    \"occlusion\":Occlusion,\n",
    "    # \"augmented_occlusion\":AugmentedOcclusion,\n",
    "    \"dyna_mask\":DynaMask,\n",
    "    \"feature_ablation\":FeatureAblation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(args.seed)\n",
    "# Disable cudnn if using cuda accelerator.\n",
    "# Please see https://captum.ai/docs/faq#how-can-i-resolve-cudnn-rnn-backward-error-for-rnn-or-lstm-network\n",
    "# args.use_gpu = False\n",
    "\n",
    "assert args.task_name == 'long_term_forecast', \"Only long_term_forecast is supported for now\"\n",
    "Exp = Exp_Long_Term_Forecast\n",
    "\n",
    "setting = stringify_setting(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)  # set experiments\n",
    "exp.model.load_state_dict(\n",
    "    torch.load(os.path.join('checkpoints/' + setting, 'checkpoint.pth'))\n",
    ")\n",
    "result_folder = './results/' + setting + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp.model\n",
    "model.eval()\n",
    "\n",
    "# only need to output targets, sinec interpretation is based on outputs\n",
    "assert not exp.args.output_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 73\n"
     ]
    }
   ],
   "source": [
    "flag = 'test'\n",
    "_, dataloader = exp._get_data(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_metric_map = {\n",
    "    'mae': mae, 'mse': mse\n",
    "}\n",
    "areas = [0.03, 0.05, 0.1, 0.2]\n",
    "\n",
    "explainers = ['deep_lift', 'feature_ablation'] # explainers = args.explainers\n",
    "explainers_map = dict()\n",
    "for name in explainers:\n",
    "    explainers_map[name] = explainer_name_map[name](model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# \"zero\", \"aug\", \"random\"\n",
    "# performance order random > zero > aug\n",
    "baseline_mode = \"random\" \n",
    "\n",
    "result_columns = ['batch_index', 'explainer', 'metric', 'area', 'comp', 'suff']\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    enumerate(dataloader), total=len(dataloader), disable=False\n",
    ")\n",
    "for batch_index, (batch_x, batch_y, batch_x_mark, batch_y_mark) in progress_bar:\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()\n",
    "    # outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    \n",
    "    # baseline must be a scaler or tuple of tensors with same dimension as input\n",
    "    baselines = get_baseline(batch_x, mode=baseline_mode)\n",
    "    additional_forward_args = (batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "    # get attributions\n",
    "    for name in explainers:\n",
    "        explainer = explainers_map[name]\n",
    "        attr = compute_attr(\n",
    "            batch_x, baselines, explainer, additional_forward_args, args\n",
    "        )\n",
    "    \n",
    "        # get scores\n",
    "        for area in areas:\n",
    "            for metric_name, metric in expl_metric_map.items():\n",
    "                error_comp = metric(\n",
    "                    model, inputs=batch_x, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=True\n",
    "                )\n",
    "                \n",
    "                error_suff = metric(\n",
    "                    model, inputs=batch_x, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=False\n",
    "                )\n",
    "           \n",
    "                result_row = [batch_index, name, metric_name, area, error_comp, error_suff]\n",
    "                results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           explainer metric  area        comp        suff\n",
      "0          deep_lift    mae  0.03   22.387512   47.552436\n",
      "1          deep_lift    mae  0.05   35.472929   34.969124\n",
      "2          deep_lift    mae  0.10   62.132083   12.359752\n",
      "3          deep_lift    mae  0.20   80.801300   15.408948\n",
      "4          deep_lift    mse  0.03   22.275765  100.830368\n",
      "5          deep_lift    mse  0.05   54.752081   56.914517\n",
      "6          deep_lift    mse  0.10  165.784731    9.525279\n",
      "7          deep_lift    mse  0.20  286.879962   17.974950\n",
      "8   feature_ablation    mae  0.03   22.090495   48.157625\n",
      "9   feature_ablation    mae  0.05   34.997378   35.562492\n",
      "10  feature_ablation    mae  0.10   61.651758   12.793189\n",
      "11  feature_ablation    mae  0.20   79.969749   13.870515\n",
      "12  feature_ablation    mse  0.03   21.877092  102.763078\n",
      "13  feature_ablation    mse  0.05   53.530500   58.256120\n",
      "14  feature_ablation    mse  0.10  163.161661   10.077021\n",
      "15  feature_ablation    mse  0.20  279.247916   15.032560\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=result_columns)\n",
    "results_df = results_df.groupby(['explainer', 'metric', 'area'])[['comp', 'suff']].aggregate('mean').reset_index()\n",
    "# results_df.round(6).to_csv(os.path.join(result_folder, 'interpretation_results.csv'), index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [12:00<00:00, 144.15s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "baseline_mode = 'random'\n",
    "result_columns = ['batch_index', 'explainer', 'metric', 'area', 'comp', 'suff']\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    enumerate(dataloader), total=len(dataloader), disable=False\n",
    ")\n",
    "for batch_index, (batch_x, batch_y, batch_x_mark, batch_y_mark) in progress_bar:\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()\n",
    "    # outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    \n",
    "    inputs = batch_x\n",
    "    # baseline must be a scaler or tuple of tensors with same dimension as input\n",
    "    baselines = get_baseline(inputs, mode=baseline_mode)\n",
    "    additional_forward_args = (batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "    for name in explainers:\n",
    "        explainer = TSRTunnel(explainers_map[name])\n",
    "        attr = compute_tsr_attr(\n",
    "            args, explainer, inputs=inputs, \n",
    "            sliding_window_shapes=(1,1), \n",
    "            strides=1, baselines=baselines,\n",
    "            additional_forward_args=additional_forward_args\n",
    "        )\n",
    "\n",
    "        # get scores\n",
    "        for area in areas:\n",
    "            for metric_name, metric in expl_metric_map.items():\n",
    "                error_comp = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=True\n",
    "                )\n",
    "                \n",
    "                error_suff = metric(\n",
    "                    model, inputs=inputs, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=False\n",
    "                )\n",
    "            \n",
    "                result_row = [batch_index, name, metric_name, area, error_comp, error_suff]\n",
    "                results.append(result_row)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          explainer metric  area        comp        suff\n",
      "0  feature_ablation    mae  0.03   18.268983   51.226972\n",
      "1  feature_ablation    mae  0.05   31.097562   38.407842\n",
      "2  feature_ablation    mae  0.10   58.866410   13.026361\n",
      "3  feature_ablation    mae  0.20   69.281813    9.093104\n",
      "4  feature_ablation    mse  0.03   15.637448  114.791965\n",
      "5  feature_ablation    mse  0.05   42.280784   66.530092\n",
      "6  feature_ablation    mse  0.10  146.903009   10.185606\n",
      "7  feature_ablation    mse  0.20  207.503314    6.183767\n"
     ]
    }
   ],
   "source": [
    "tsr_results_df = pd.DataFrame(results, columns=result_columns)\n",
    "tsr_results_df = tsr_results_df.groupby(['explainer', 'metric', 'area'])[['comp', 'suff']].aggregate('mean').reset_index()\n",
    "# tsr_results_df.round(6).to_csv(os.path.join(result_folder, 'interpretation_results_tsr.csv'), index=False)\n",
    "print(tsr_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal_mask = torch.zeros_like(batch_x, dtype=int)\n",
    "# for t in range(batch_x.shape[1]):\n",
    "#     temporal_mask[:, t] = t\n",
    "\n",
    "# explainer = FeatureAblation(model)\n",
    "# time_score = explainer.attribute(\n",
    "#     inputs=(batch_x),\n",
    "#     baselines=(batch_x*0),\n",
    "#     additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark),\n",
    "#     target=0,\n",
    "#     feature_mask=temporal_mask\n",
    "# )\n",
    "# print(score.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
