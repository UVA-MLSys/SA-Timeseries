{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import *\n",
    "from tint.metrics import mse, mae\n",
    "import tint, gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.explainer import *\n",
    "from utils.tsr_tunnel import TSRTunnel\n",
    "from exp.exp_interpret import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import (\n",
    "    DeepLift,\n",
    "    GradientShap,\n",
    "    IntegratedGradients,\n",
    "    Lime\n",
    ")\n",
    "\n",
    "from tint.attr import (\n",
    "    AugmentedOcclusion,\n",
    "    DynaMask, Fit,\n",
    "    Occlusion, \n",
    "    FeatureAblation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser()\n",
    "argv = \"\"\"\n",
    "  --task_name long_term_forecast \\\n",
    "  --use_gpu \\\n",
    "  --result_path scratch \\\n",
    "  --root_path ./dataset/illness/ \\\n",
    "  --data_path national_illness.csv \\\n",
    "  --model LSTM \\\n",
    "  --features MS \\\n",
    "  --seq_len 36 \\\n",
    "  --label_len 12 \\\n",
    "  --pred_len 24 \\\n",
    "  --n_features 7\n",
    "\"\"\".split()\n",
    "args = parser.parse_args(argv)\n",
    "\n",
    "# Disable cudnn if using cuda accelerator.\n",
    "# Please see https://captum.ai/docs/faq#how-can-i-resolve-cudnn-rnn-backward-error-for-rnn-or-lstm-network\n",
    "# args.use_gpu = False\n",
    "initial_setup(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Experiments will be saved in scratch\\national_illness_LSTM\n",
      "test 73\n",
      "Loading model from scratch\\national_illness_LSTM\\checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "if args.task_name == 'classification': Exp = Exp_Classification\n",
    "else: Exp = Exp_Long_Term_Forecast\n",
    "exp = Exp(args)  # set experiments\n",
    "_, dataloader = exp._get_data(args.flag)\n",
    "\n",
    "exp.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp.model\n",
    "model.eval()\n",
    "\n",
    "# only need to output targets, sinec interpretation is based on outputs\n",
    "assert not exp.args.output_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_metric_map = {\n",
    "    'mae': mae, 'mse': mse\n",
    "}\n",
    "areas = [0.03, 0.05, 0.1, 0.2]\n",
    "\n",
    "explainers = ['deep_lift', 'feature_ablation'] # explainers = args.explainers\n",
    "explainers_map = dict()\n",
    "for name in explainers:\n",
    "    explainers_map[name] = explainer_name_map[name](model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# \"zero\", \"aug\", \"random\"\n",
    "# performance order random > zero > aug\n",
    "baseline_mode = \"random\" \n",
    "\n",
    "result_columns = ['batch_index', 'explainer', 'metric', 'area', 'comp', 'suff']\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    enumerate(dataloader), total=len(dataloader), disable=False\n",
    ")\n",
    "for batch_index, (batch_x, batch_y, batch_x_mark, batch_y_mark) in progress_bar:\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()\n",
    "    # outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    \n",
    "    # baseline must be a scaler or tuple of tensors with same dimension as input\n",
    "    baselines = get_baseline(batch_x, mode=baseline_mode)\n",
    "    additional_forward_args = (batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "    # get attributions\n",
    "    for name in explainers:\n",
    "        explainer = explainers_map[name]\n",
    "        attr = compute_regressor_attr(\n",
    "            batch_x, baselines, explainer, additional_forward_args, args\n",
    "        )\n",
    "    \n",
    "        # get scores\n",
    "        for area in areas:\n",
    "            for metric_name, metric in expl_metric_map.items():\n",
    "                error_comp = metric(\n",
    "                    model, inputs=batch_x, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=True\n",
    "                )\n",
    "                \n",
    "                error_suff = metric(\n",
    "                    model, inputs=batch_x, \n",
    "                    attributions=attr, baselines=baselines, \n",
    "                    additional_forward_args=additional_forward_args,\n",
    "                    topk=area, mask_largest=False\n",
    "                )\n",
    "           \n",
    "                result_row = [batch_index, name, metric_name, area, error_comp, error_suff]\n",
    "                results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y, batch_x_mark, batch_y_mark = next(iter(dataloader))\n",
    "batch_x = batch_x.float().to(exp.device)\n",
    "batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "# decoder input\n",
    "dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = get_total_data(dataloader, exp.device)\n",
    "inputs = (batch_x, batch_x_mark)\n",
    "additional_forward_args = (dec_inp, batch_y_mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WinIT:\n",
    "    def __init__(self, model, data, args):\n",
    "        self.model = model\n",
    "        self.args = args\n",
    "        self.seq_len = args.seq_len\n",
    "        self.task_name = args.task_name\n",
    "        self.data = data\n",
    "        self.rng = np.random.default_rng(args.seed)\n",
    "        \n",
    "        if self.task_name =='classification':\n",
    "            self.metric = 'kl'\n",
    "        else:\n",
    "            self.metric = 'pd'\n",
    "        \n",
    "    def _compute_metric(\n",
    "        self, p_y_exp: torch.Tensor, p_y_hat: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the metric for comparisons of two distributions.\n",
    "\n",
    "        Args:\n",
    "            p_y_exp:\n",
    "                The current expected distribution. Shape = (batch_size, num_states)\n",
    "            p_y_hat:\n",
    "                The modified (counterfactual) distribution. Shape = (batch_size, num_states)\n",
    "\n",
    "        Returns:\n",
    "            The result Tensor of shape (batch_size).\n",
    "\n",
    "        \"\"\"\n",
    "        if self.metric == \"kl\":\n",
    "            return torch.sum(torch.nn.KLDivLoss(reduction=\"none\")(torch.log(p_y_hat), p_y_exp), -1)\n",
    "        if self.metric == \"js\":\n",
    "            average = (p_y_hat + p_y_exp) / 2\n",
    "            lhs = torch.nn.KLDivLoss(reduction=\"none\")(torch.log(average), p_y_hat)\n",
    "            rhs = torch.nn.KLDivLoss(reduction=\"none\")(torch.log(average), p_y_exp)\n",
    "            return torch.sum((lhs + rhs) / 2, -1)\n",
    "        if self.metric == \"pd\":\n",
    "            diff = torch.abs(p_y_hat - p_y_exp)\n",
    "            \n",
    "            # sum over all dimension except batch\n",
    "            summed = torch.sum(diff, dim=-1) # tuple(range(diff.ndim)[1:])\n",
    "            return summed\n",
    "        \n",
    "        raise Exception(f\"unknown metric. {self.metric}\")\n",
    "    \n",
    "    def generate_counterfactuals(self, batch_size, input_index, feature_index):\n",
    "        \n",
    "        choices = self.data[input_index][:][:, :, feature_index].reshape(-1)\n",
    "        sampled_index = np.random.choice(range(len(choices)), size=(batch_size*self.seq_len))\n",
    "        samples = choices[sampled_index].reshape((batch_size, self.seq_len))\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def format_output(self, outputs):\n",
    "        if self.task_name == 'classification':\n",
    "            return torch.nn.functional.softmax(outputs, dim=1)\n",
    "        else:\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "            return outputs\n",
    "            \n",
    "    def attribute(\n",
    "        self, inputs, additional_forward_args, \n",
    "        attributions_fn=None\n",
    "    ):\n",
    "        model = self.model\n",
    "        y_original = self.format_output(model(*inputs, *additional_forward_args))\n",
    "        attr = []\n",
    "        \n",
    "        for input_index, input in enumerate(inputs):\n",
    "            batch_size, seq_len, n_features = input.shape\n",
    "            iS_array = torch.zeros(size=(batch_size, self.args.pred_len, seq_len, n_features))\n",
    "            \n",
    "            for feature in range(n_features):\n",
    "                cloned = input.clone()\n",
    "                counterfactuals = self.generate_counterfactuals(\n",
    "                    batch_size, input_index, feature\n",
    "                )\n",
    "                \n",
    "                for t in range(seq_len)[::-1]:\n",
    "                    # mask last t timesteps\n",
    "                    cloned[:, t:, feature] = counterfactuals[:, t:]\n",
    "                    \n",
    "                    inputs_hat = []\n",
    "                    for i in range(len(inputs)):\n",
    "                        if i == input_index: inputs_hat.append(cloned)\n",
    "                        else: inputs_hat.append(inputs[i])\n",
    "                \n",
    "                    y_perturbed = self.format_output(model(*tuple(inputs_hat), *additional_forward_args))\n",
    "                    \n",
    "                    iSab = self._compute_metric(y_original, y_perturbed)\n",
    "                    iSab = torch.clip(iSab, -1e6, 1e6)\n",
    "                    iS_array[:, :, t, feature] = iSab\n",
    "                        \n",
    "            iS_array[:, :, 1:] -= iS_array[:, :, :-1]\n",
    "            \n",
    "            if attributions_fn is not None:\n",
    "                attr.append(attributions_fn(iS_array))\n",
    "            else: attr.append(iS_array)\n",
    "            \n",
    "        return tuple(attr)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return 'WinIT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = WinIT(exp.model, total_data, args)\n",
    "attr = explainer.attribute(inputs, additional_forward_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 24, 36, 7])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal_mask = torch.zeros_like(batch_x, dtype=int)\n",
    "# for t in range(batch_x.shape[1]):\n",
    "#     temporal_mask[:, t] = t\n",
    "\n",
    "# explainer = FeatureAblation(model)\n",
    "# time_score = explainer.attribute(\n",
    "#     inputs=(batch_x),\n",
    "#     baselines=(batch_x*0),\n",
    "#     additional_forward_args=(batch_x_mark, dec_inp, batch_y_mark),\n",
    "#     target=0,\n",
    "#     feature_mask=temporal_mask\n",
    "# )\n",
    "# print(score.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
