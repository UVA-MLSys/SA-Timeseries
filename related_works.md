# Related works
| Title | Published in | Summary |
|:---:|:---:|:---|
[Encoding time-series explanations through self-supervised model behavior consistency](https://proceedings.neurips.cc/paper_files/paper/2023/file/65ea878cb90b440e8b4cd34fe0959914-Paper-Conference.pdf) | NeurIPS 2024 | TIMEX proposed a consistency model for training interpretable surrogates. This preserves the latent space induced by the pre-trained time series model and provides faithful and discrete attribution.  |
|[Temporal Dependencies in Feature Importance for Time Series Prediction](https://arxiv.org/pdf/2107.14317) | ICLR 2022 | Windowed Feature Importance in Time (WinIT) proposed a sliding window-based approach to calculate delayed feature importance.
| [CGS-Mask: Making Time Series Predictions Intuitive for All](https://ojs.aaai.org/index.php/AAAI/article/view/29325/30499) | AAAI 2024 | Proposes a cellular genetic strip mask-based saliency approach to consider the time-sensitive nature of time series applications while giving binary importance to features instead of a numerical score. |
| [Benchmarking deep learning interpretability in time series predictions](https://proceedings.neurips.cc/paper_files/paper/2020/file/47a3893cc405396a5c30d91320572d6d-Paper.pdf) | NeurIPS 2020 | Propose and report multiple saliency evaluation metrics and a two-step temporal saliency rescaling (TSR) approach that first calculates the importance of each time step before calculating the importance of each feature at a time step.
| [Evaluation of post-hoc interpretability methods in time-series classification](https://www.nature.com/articles/s42256-023-00620-w) | Nature 2023 | Proposed a framework with quantitative metrics to assess the performance of existing post-hoc interpretability methods, particularly in time-series classification. |
| [Evaluation of interpretability methods for multivariate time series forecasting](https://link.springer.com/article/10.1007/s10489-021-02662-2) | Applied Intelligence 2022 | Benchmarked their interpretation on several regression datasets using multi-horizon fixed input window setting, but didn't consider time dimension separately. |
| [What went wrong and when? Instance-wise feature importance for time-series black-box models]() | NeurIPS 2020 | Feature Importance for Time-series (FIT) measured each observation's importance to prediction change at the same time step using the KL-divergence base score, however, it only supports classification tasks.|
| [Interpreting County-Level COVID-19 Infections using Transformer and Deep Learning Time Series Models](https://ieeexplore.ieee.org/iel7/10224635/10224668/10224685.pdf) | ICDH 2023 | Time series interpretation with Attention weights |
| [Explainable artificial intelligence (xai) on timeseries data: A survey](https://arxiv.org/pdf/2104.00950) | arxiv | Survey paper in time series interpretation
| [Deep learning for time series forecasting: Tutorial and literature survey](https://dl.acm.org/doi/pdf/10.1145/3533382) | ACM Computing Surveys 2022 | Survey paper |
| [Interpretation of Time-Series Deep Models: A Survey](https://arxiv.org/pdf/2305.14582) | arxiv | Survey paper |